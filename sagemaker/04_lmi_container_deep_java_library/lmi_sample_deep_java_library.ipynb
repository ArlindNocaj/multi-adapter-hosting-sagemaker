{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1982e44-5821-4c04-b6a6-fc3814ca3677",
   "metadata": {},
   "source": [
    "## Running a model with optimized inference by just providing the model id\n",
    "Get started by reading [here](https://docs.djl.ai/docs/serving/serving/docs/lmi/user_guides/starting-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e0edae-f3f7-42b8-b6ff-1dcffe96efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes SageMaker Python SDK is installed. For example: \"pip install sagemaker\"\n",
    "import sagemaker\n",
    "from sagemaker import image_uris, Model, Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Setup role and sagemaker session\n",
    "iam_role = sagemaker.get_execution_role() \n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1163c9-3df9-4dc0-920b-cde712da2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "# Fetch the uri of the LMI container that supports vLLM, LMI-Dist, HuggingFace Accelerate backends\n",
    "lmi_image_uri = image_uris.retrieve(framework=\"djl-lmi\", version=\"0.28.0\", region=region)\n",
    "\n",
    "# Create the SageMaker Model object. In this example we let LMI configure the deployment settings based on the model architecture  \n",
    "model = Model(\n",
    "  image_uri=lmi_image_uri,\n",
    "  role=iam_role,\n",
    "  env={\n",
    "    \"HF_MODEL_ID\": \"TheBloke/Llama-2-7B-fp16\",\n",
    "  }\n",
    ")\n",
    "\n",
    "# Deploy your model to a SageMaker Endpoint and create a Predictor to make inference requests\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"llama-7b-endpoint\")\n",
    "model.deploy(instance_type=\"ml.g5.2xlarge\", initial_instance_count=1, endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600a4b39-b37c-4b7f-8ade-549d55dedc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictor from endpoint name and component name, if there is multiple components deployed\n",
    "#component_name=\"you_name\"\n",
    "#endpoint_name=\"endpoint_name\"\n",
    "predictor = Predictor(\n",
    "  #component_name=component_name,\n",
    "  endpoint_name=endpoint_name,\n",
    "  sagemaker_session=sagemaker_session,\n",
    "  serializer=JSONSerializer(),\n",
    "  deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6e8ad7-82b8-40d9-9e41-a2cdfe015cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': ' made, and no, this isn\\'t a joke. Some years ago the consulting firm the Boston Consulting Group thought up a new strategy for the giant German windows and doors specialist INTERIOR Concepts in Munich. Among themselves, the consultants called the strategy \"The Diamondback Terrapin.\" That was the name of a rare turtle that\\'s a native of the Atlantic Coast and whose markings make it all the more desirable.\\nIn the native countries of the German subsidiaries in Belgium and the United States (formerly Germany), the terrapin is considered a landmark. INTERIOR Concepts wants better sales figures from its foreign subsidiaries in Caernarfon / Wales, Freiburg, Dubai and Texas. Former top managers were replaced one by one until Dr. Aldo Kepp before long but once again in charge of marketing and sales, at the beginning of this year.\\nProvided INTERIOR Concepts is succeeded in optimizing sales, the diamondback terrapin could \"win this year\\'s Olympic gold-selling regions.\" The blogger Turtle - who has been writing about the'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an inference request against the llama2-7b endpoint\n",
    "outputs = predictor.predict({\n",
    "  \"inputs\": \"The diamondback terrapin was the first reptile to be\",\n",
    "  \"parameters\": {\n",
    "    \"do_sample\": True,\n",
    "    \"max_new_tokens\": 256,\n",
    "  }\n",
    "})\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537f8bd-6052-4e17-8c6c-4adc3b66e56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
