{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from utils_cifar import get_train_data_loader, get_test_data_loader, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Downloading data\n",
    "We retrieve the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/cifar-10-batches-py/batches.meta') and \\\n",
    "        os.path.isfile('./data/cifar-10-python.tar.gz') :\n",
    "    print('Training and evaluation datasets exist')\n",
    "    test_loader = get_test_data_loader(False)\n",
    "else:\n",
    "    print('Downloading training and evaluation dataset')\n",
    "    test_loader = get_test_data_loader(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the SageMaker SDK without actually running remote jobs, using our local compute where this notebook runs. [Local mode](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode) improves the development experience by enabling you to test everything runs correctly with the selected pre-built or custom container, and that the SageMaker interfaces are being used properly, ensuring parity between local experimentation and full on remote jobs. You can also use it to train on local data and output the resulting model to a local directory, and debug the .fit method, stepping through your training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session_local = LocalSession()\n",
    "sagemaker_session_local.config = {'local': {'local_code': True}}\n",
    "\n",
    "# dummy role\n",
    "dummy_role = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'\n",
    "\n",
    "cifar10_estimator = PyTorch(entry_point='cifar10_pytorch.py',\n",
    "                            source_dir='./code',\n",
    "                            role=dummy_role,\n",
    "                            framework_version='1.8',\n",
    "                            py_version='py3',\n",
    "                            # image_uri='custom-container',\n",
    "                            instance_count=1,\n",
    "                            instance_type='local_gpu',\n",
    "                            output_path='file://model/',\n",
    "                            hyperparameters={\n",
    "                                'epochs': 1,\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_estimator.fit(inputs={'training':'file://./data/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sess = sagemaker.Session()\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "bucket = sm_sess.default_bucket()\n",
    "print('Default role:', sm_role)\n",
    "print('Default bucket:', bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sm-core-testing'\n",
    "inputs_s3 = sm_sess.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix+'/data')\n",
    "print(inputs_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you just want to upload the model you trained locally\n",
    "# model_s3_uri = sm_sess.upload_data(path=\"model/model.tar.gz\", bucket=bucket, key_prefix=prefix+'/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_estimator_remote = PyTorch( entry_point='cifar10_pytorch.py',\n",
    "                                    source_dir='./code',\n",
    "                                    role=sm_role,\n",
    "                                    framework_version='1.8',\n",
    "                                    py_version='py3',\n",
    "                                    # image_uri='046234989437.dkr.ecr.us-east-1.amazonaws.com/test-az-sm-core-custom:20220628203731',\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.g5.xlarge',\n",
    "                                    hyperparameters={\n",
    "                                        'epochs': 1,\n",
    "                                    },\n",
    "                                    output_path=f's3://{bucket}/{prefix}/train_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_estimator_remote.fit(inputs={'training':inputs_s3},\n",
    "                             job_name=f'test-sm-core-{sagemaker.utils.sagemaker_short_timestamp()}'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_estimator_remote.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'test-sm-core-custom'\n",
    "!sh ./docker_custom/build_and_push.sh $image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve pre-built Deep Learning Container images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "sagemaker.image_uris.retrieve(region='us-east-1',framework='pytorch',version='1.8',py_version='py3',instance_type='ml.p3.2xlarge',image_scope='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model to real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could go straight from training to deployment, but we use PyTorchModel here to showcase just deploying a model artifact\n",
    "# cifar10_estimator_remote.deploy(initial_instance_count=1,instance_type='ml.c5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "env_vars = {\n",
    "    \"SAGEMAKER_TS_BATCH_SIZE\": \"4\",\n",
    "    \"SAGEMAKER_TS_MAX_BATCH_DELAY\": \"100000\"\n",
    "}\n",
    "\n",
    "pt_model = PyTorchModel(model_data=cifar10_estimator_remote.model_data,\n",
    "                        # model_data=model_s3_uri,\n",
    "                        role=sm_role,\n",
    "                        entry_point='cifar10_pytorch.py',\n",
    "                        source_dir='code',\n",
    "                        framework_version='1.8',\n",
    "                        py_version='py3')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pt_model.deploy(initial_instance_count=1,instance_type='ml.g4dn.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you want to load a predictor again after you've lost the variables\n",
    "# from sagemaker.predictor import Predictor\n",
    "# from sagemaker.serializers import NumpySerializer\n",
    "# from sagemaker.deserializers import NumpyDeserializer\n",
    "\n",
    "# predictor = Predictor(endpoint_name='pytorch-inference-2022-07-05-16-18-01-354',serializer=NumpySerializer(),deserializer=NumpyDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=4096, max_concurrency=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_serverless = pt_model.deploy(serverless_inference_config=serverless_config,wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy an asynchronous endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(output_path=f\"s3://{bucket}/{prefix}/async_results/\",\n",
    "                                    max_concurrent_invocations_per_instance=10,\n",
    "                                    notification_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_async = pt_model.deploy(async_inference_config=async_config,\n",
    "                                  instance_type='ml.g4dn.xlarge',\n",
    "                                  initial_instance_count=1,\n",
    "                                  wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor_async import AsyncPredictor\n",
    "\n",
    "predictor_async_wrapper = AsyncPredictor(predictor=predictor_async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do inference on the hosted/serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5   # unnormalize\n",
    "  npimg = img.numpy()   # convert from tensor\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def do_inference(predictor, testloader):\n",
    "    print('Sending requests to SM Endpoint')\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    print(len(images))\n",
    "\n",
    "    outputs = predictor.predict(images.numpy())\n",
    "\n",
    "    _, predicted = torch.max(torch.from_numpy(np.array(outputs)), 1)\n",
    "    \n",
    "    print('Predicted: ', ' '.join('%4s' % classes[predicted[j]]\n",
    "                                  for j in range(4)))\n",
    "\n",
    "    for i in range(4):  # show just the frogs  # 6 = frog\n",
    "        imshow(tv.utils.make_grid(images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_inference(predictor,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do inference on the async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5   # unnormalize\n",
    "  npimg = img.numpy()   # convert from tensor\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def do_inference_async(predictor, testloader):\n",
    "  print('Sending requests to SM Endpoint')\n",
    "  dataiter = iter(testloader)\n",
    "  images, labels = dataiter.next()\n",
    "  print(len(images))\n",
    "\n",
    "\n",
    "  async_output = predictor.predict_async(data=images.numpy())\n",
    "\n",
    "  return async_output\n",
    "\n",
    "def process_async_response(response):\n",
    "  _, predicted = torch.max(torch.from_numpy(response), 1)\n",
    "  print('Predicted: ', ' '.join('%4s' % classes[predicted[j]]\n",
    "                                  for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = predictor_async_wrapper.predict_async(data=images.numpy())\n",
    "response = do_inference_async(predictor_async_wrapper,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_array = response.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "591ade058296000ef487104c42d37478df75296e039f312fe940d4accf2fd7b8"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
